{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Intellisense\n",
    "\n",
    "%config IPCompleter.greedy=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from searchtweets import ResultStream, gen_rule_payload, load_credentials\n",
    "from searchtweets import collect_results\n",
    "from twitter import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "from twitter import *\n",
    "import pandas as pd\n",
    "\n",
    "auth = tweepy.OAuthHandler(twittercreds.CONSUMER_KEY,twittercreds.CONSUMER_SECRET)\n",
    "auth.set_access_token(twittercreds.ACCESS_TOKEN,twittercreds.ACCESS_TOKEN_SECRET)\n",
    "\n",
    "\n",
    "api = tweepy.API(auth,wait_on_rate_limit=True, wait_on_rate_limit_notify=True)\n",
    "\n",
    "\n",
    "\n",
    "df = pd.DataFrame(columns = ['Tweets','Tweetid', 'User','handlename','User_statuses_count', \n",
    "                             'user_followers', 'User_location', 'User_verified',\n",
    "                             'fav_count', 'rt_count', 'tweet_date','hashtags','tweet_img_url','tweet_img_url_extended','media_url','query_criteria'])\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def stream(data, file_name):\n",
    "def stream(data):\n",
    "    i = 0\n",
    "    for tweet in tweepy.Cursor(api.search, q=data, count=100, lang='en',tweet_mode='extended').items():\n",
    "        if (not tweet.retweeted) and ('RT @' not in tweet.full_text):\n",
    "            print(i, end='\\r')\n",
    "            df.loc[i, 'Tweets'] = tweet.full_text\n",
    "            df.loc[i,'Tweetid'] = tweet.id\n",
    "            df.loc[i, 'User'] = tweet.user.name\n",
    "            df.loc[i,'handlename'] = tweet.user.screen_name\n",
    "            df.loc[i, 'User_statuses_count'] = tweet.user.statuses_count\n",
    "            df.loc[i, 'user_followers'] = tweet.user.followers_count\n",
    "            df.loc[i, 'User_location'] = tweet.user.location\n",
    "            df.loc[i, 'User_verified'] = tweet.user.verified\n",
    "            df.loc[i, 'fav_count'] = tweet.favorite_count\n",
    "            df.loc[i, 'rt_count'] = tweet.retweet_count\n",
    "            df.loc[i, 'tweet_date'] = tweet.created_at\n",
    "            df.loc[i,'hashtags'] = tweet.entities['hashtags']\n",
    "            df.loc[i,'query_criteria'] = 'emerging_tech'\n",
    "            try:\n",
    "                df.loc[i,'tweet_img_url'] = tweet.entities['media'][0]['media_url']\n",
    "                df.loc[i,'tweet_img_url_extended'] = tweet.entities['media'][0]['expanded_url']\n",
    "            except KeyError:\n",
    "                df.loc[i,'tweet_img_url'] = 'Null'\n",
    "                df.loc[i,'tweet_img_url_extended'] = 'Null'\n",
    "            df.loc[i,'media_url'] = tweet.entities['urls']\n",
    "            \n",
    "            #df.to_excel('{}.xlsx'.format(file_name))\n",
    "            i+=1\n",
    "            if i == 50:\n",
    "                break\n",
    "            else:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49\r"
     ]
    }
   ],
   "source": [
    "stream(data = ['the future -filter:retweets','tech -filter:retweets'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv('final.csv')\n",
    "#len(df)\n",
    "import json\n",
    "\n",
    "#data = json.dumps(strema[1]._json)\n",
    "#dg = json.loads(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please visit this URL to authorize this application: https://accounts.google.com/o/oauth2/auth?response_type=code&client_id=275664291874-jutmedsp4bmt6o40tm0809phnk9tnruc.apps.googleusercontent.com&redirect_uri=http%3A%2F%2Flocalhost%3A8080%2F&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fbigquery&state=0GiMqhS7cERGrT6rp1U455WDUbHQk2&access_type=offline\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#create a client instance for you project\n",
    "from google.cloud import bigquery\n",
    "from google.oauth2 import service_account\n",
    "\n",
    "\n",
    "#access project via user account\n",
    "from google_auth_oauthlib import flow\n",
    "\n",
    "# TODO: Uncomment the line below to set the `launch_browser` variable.\n",
    "launch_browser = True\n",
    "#\n",
    "# The `launch_browser` boolean variable indicates if a local server is used\n",
    "# as the callback URL in the auth flow. A value of `True` is recommended,\n",
    "# but a local server does not work if accessing the application remotely,\n",
    "# such as over SSH or from a remote Jupyter notebook.\n",
    "\n",
    "appflow = flow.InstalledAppFlow.from_client_secrets_file(\n",
    "    r\"C:\\Users\\varunn\\Documents\\kaggle-competiton\\credentials\\credentials.json\",\n",
    "    scopes=['https://www.googleapis.com/auth/bigquery'])\n",
    "\n",
    "if launch_browser:\n",
    "    appflow.run_local_server()\n",
    "else:\n",
    "    appflow.run_console()\n",
    "\n",
    "credentials = appflow.credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID = 'rgadata-m11'\n",
    "client = bigquery.Client(project=PROJECT_ID,location='US',credentials=credentials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Table(TableReference(DatasetReference('rgadata-m11', 'sandboxm11'), 'twitterstream'))"
      ]
     },
     "execution_count": 650,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_id = f\"{PROJECT_ID}.sandboxm11.twitterstream\"\n",
    "\n",
    "schema=[\n",
    "        # Specify the type of columns whose type cannot be auto-detected. For\n",
    "        # example the \"title\" column uses pandas dtype \"object\", so its\n",
    "        # data type is ambiguous.\n",
    "        \n",
    "        bigquery.SchemaField(\"tweetid\", bigquery.enums.SqlTypeNames.INT64),\n",
    "        bigquery.SchemaField(\"tweets\", bigquery.enums.SqlTypeNames.STRING),    \n",
    "        bigquery.SchemaField(\"tweet_date\", bigquery.enums.SqlTypeNames.DATETIME),\n",
    "        bigquery.SchemaField(\"media_url\", bigquery.enums.SqlTypeNames.STRING),\n",
    "        \n",
    "        #bigquery.SchemaField(\"media_url\",\"RECORD\",mode=\"REPEATED\",\n",
    "        #fields=[bigquery.SchemaField(\"url\", \"STRING\", mode=\"NULLABLE\"),],),\n",
    "    \n",
    "        bigquery.SchemaField(\"tweet_img_url\", bigquery.enums.SqlTypeNames.STRING),\n",
    "        bigquery.SchemaField(\"tweet_img_url_extended\", bigquery.enums.SqlTypeNames.STRING),\n",
    "        bigquery.SchemaField(\"hashtags\", bigquery.enums.SqlTypeNames.STRING),\n",
    "        \n",
    "        #bigquery.SchemaField(\"hashtags\",\"RECORD\",mode=\"REPEATED\",\n",
    "        #fields=[bigquery.SchemaField(\"hash\", \"STRING\", mode=\"NULLABLE\"),],),\n",
    "    \n",
    "\n",
    "        bigquery.SchemaField(\"user\", bigquery.enums.SqlTypeNames.STRING),\n",
    "        bigquery.SchemaField(\"handlename\", bigquery.enums.SqlTypeNames.STRING),\n",
    "        bigquery.SchemaField(\"user_statuses_count\", bigquery.enums.SqlTypeNames.INT64),\n",
    "        bigquery.SchemaField(\"user_followers\", bigquery.enums.SqlTypeNames.INT64),\n",
    "        bigquery.SchemaField(\"user_location\", bigquery.enums.SqlTypeNames.STRING),\n",
    "        bigquery.SchemaField(\"user_verified\", bigquery.enums.SqlTypeNames.BOOL),\n",
    "        bigquery.SchemaField(\"fav_count\", bigquery.enums.SqlTypeNames.INT64),\n",
    "        bigquery.SchemaField(\"rt_count\", bigquery.enums.SqlTypeNames.INT64),\n",
    "        bigquery.SchemaField(\"query_criteria\", bigquery.enums.SqlTypeNames.STRING)\n",
    "        \n",
    "\n",
    "    ]\n",
    "table = bigquery.Table(table_id, schema=schema)\n",
    "#create a table in dataset\n",
    "client.create_table(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "dataset_id = 'sandboxm11'\n",
    "table_id = 'twitterstream'\n",
    "\n",
    "table_ref = client.dataset(dataset_id).table(table_id)\n",
    "table = client.get_table(table_ref)\n",
    "\n",
    "#tell client everything it needs to know to upload your data\n",
    "#dataset_ref = client.dataset(dataset_id)\n",
    "#table_ref = dataset_ref.table(table_id)\n",
    "#job_config.autodetect = True\n",
    "# subclass JSONEncoder\n",
    "\n",
    "tweetss= []\n",
    "\n",
    "def stream(data):\n",
    "    i = 0\n",
    "    data_tuples=[]\n",
    "    for tweet in tweepy.Cursor(api.search, q=data, count=100, lang='en',tweet_mode='extended').items():\n",
    "        tweetss.append(tweet)   \n",
    "        if (not tweet.retweeted) and ('RT @' not in tweet.full_text):\n",
    "            print(i, end='\\r')\n",
    "            \n",
    "            tweets = tweet.full_text\n",
    "            tweetid = tweet.id\n",
    "            user = tweet.user.name\n",
    "            handlename = tweet.user.screen_name\n",
    "            user_statuses_count = tweet.user.statuses_count\n",
    "            user_followers = tweet.user.followers_count\n",
    "            user_location = tweet.user.location\n",
    "            user_verified = tweet.user.verified\n",
    "            fav_count = tweet.favorite_count\n",
    "            rt_count = tweet.retweet_count\n",
    "            #tweet_date = DateTimeEncoder().encode(tweet.created_at)\n",
    "            tweet_date = tweet.created_at\n",
    "            hashtags = str(tweet.entities['hashtags'])\n",
    "            query_criteria = 'emerging_tech'\n",
    "            try:\n",
    "                tweet_img_url = tweet.entities['media'][0]['media_url']\n",
    "                tweet_img_url_extended = tweet.entities['media'][0]['expanded_url']\n",
    "                \n",
    "            except KeyError:\n",
    "                tweet_img_url = 'Null'\n",
    "                tweet_img_url_extended = 'Null'\n",
    "                \n",
    "            try:\n",
    "                media_url = tweet.entities['urls'][0]['expanded_url']\n",
    "            \n",
    "            except IndexError:\n",
    "                media_url = 'Null'\n",
    "                \n",
    "            query = \"\"\"\n",
    "                     SELECT tweetid FROM sandboxm11.twitterstream where tweetid=@tweetid;\n",
    "                    \"\"\"\n",
    "            job_config = bigquery.QueryJobConfig(query_parameters=[bigquery.ScalarQueryParameter(\"tweetid\", \"INT64\",tweetid),])\n",
    "            \n",
    "            query_job = client.query(query, job_config=job_config)\n",
    "            \n",
    "            if query_job.to_dataframe().empty:\n",
    "                rows_to_insert =[(tweetid,tweets,tweet_date,media_url,tweet_img_url,tweet_img_url_extended,hashtags,user,handlename,user_statuses_count,user_followers,user_location,user_verified,fav_count,rt_count,query_criteria)]    \n",
    "                error = client.insert_rows(table, rows_to_insert) \n",
    "            \n",
    "            i+=1\n",
    "            if i == 50:\n",
    "                break\n",
    "            else:\n",
    "                pass\n",
    "            \n",
    "            \n",
    "            #if error == []:\n",
    "            #    print(\"New rows have been added\")\n",
    "                \n",
    "            #else:\n",
    "            #    print(error)\n",
    "            #    break\n",
    "            \n",
    "    #if errors == []:\n",
    "    #    print(\"New rows have been added\")\n",
    "\n",
    "    #else:\n",
    "    #    print(errors)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49\r"
     ]
    }
   ],
   "source": [
    "stream(data = ['the future -filter:retweets','tech -filter:retweets'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
